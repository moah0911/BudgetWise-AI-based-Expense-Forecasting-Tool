#!/usr/bin/env python3
"""
Quick verification of enhanced accuracy metrics in Streamlit model comparison
"""

import pandas as pd
from pathlib import Path

def verify_accuracy_metrics():
    print("ðŸ” VERIFYING ENHANCED ACCURACY METRICS")
    print("=" * 60)
    
    # Load ML results with new metrics
    ml_file = Path("models/ml/ml_results.csv")
    if ml_file.exists():
        df = pd.read_csv(ml_file)
        print(f"âœ… ML Results loaded: {len(df)} models")
        print(f"ðŸ“Š Available columns: {df.columns.tolist()}")
        
        if 'val_r2' in df.columns and 'val_directional_accuracy' in df.columns:
            print(f"\nðŸŽ¯ NEW ACCURACY METRICS AVAILABLE:")
            for _, row in df.iterrows():
                model_name = row['model_name']
                val_mae = row['val_mae']
                val_mape = row['val_mape']
                val_r2 = row['val_r2']
                val_dir_acc = row['val_directional_accuracy']
                
                print(f"   â€¢ {model_name}:")
                print(f"     - MAE: â‚¹{val_mae:.2f}")
                print(f"     - MAPE: {val_mape:.2f}%")
                print(f"     - RÂ² Score: {val_r2:.3f}")
                print(f"     - Directional Accuracy: {val_dir_acc:.1f}%")
                print()
            
            # Test model comparison logic
            all_results = []
            for _, row in df.iterrows():
                all_results.append({
                    'Category': 'Machine Learning',
                    'Model': row['model_name'],
                    'MAE': row['val_mae'],
                    'RMSE': row['val_rmse'],
                    'MAPE': row['val_mape'],
                    'RÂ²': row['val_r2'],
                    'Directional_Accuracy': row['val_directional_accuracy']
                })
            
            results_df = pd.DataFrame(all_results)
            print(f"ðŸŽ‰ STREAMLIT COMPARISON READY:")
            print(f"   â€¢ Total models for comparison: {len(results_df)}")
            print(f"   â€¢ Best MAE: â‚¹{results_df['MAE'].min():.2f} ({results_df.loc[results_df['MAE'].idxmin(), 'Model']})")
            print(f"   â€¢ Best RÂ²: {results_df['RÂ²'].max():.3f} ({results_df.loc[results_df['RÂ²'].idxmax(), 'Model']})")
            print(f"   â€¢ Best Dir.Acc: {results_df['Directional_Accuracy'].max():.1f}% ({results_df.loc[results_df['Directional_Accuracy'].idxmax(), 'Model']})")
            
            # Check data quality
            print(f"\nðŸ“Š DATA QUALITY CHECK:")
            print(f"   â€¢ All MAE values valid: {(results_df['MAE'] > 0).all()}")
            print(f"   â€¢ All RÂ² values in range: {(results_df['RÂ²'] >= -1).all() and (results_df['RÂ²'] <= 1).all()}")
            print(f"   â€¢ All Dir.Acc values in range: {(results_df['Directional_Accuracy'] >= 0).all() and (results_df['Directional_Accuracy'] <= 100).all()}")
            
            print(f"\nâœ… SUCCESS: Enhanced accuracy metrics are working correctly!")
            print(f"ðŸš€ Streamlit app should now display all accuracy metrics including RÂ² and Directional Accuracy!")
            
        else:
            print(f"âŒ ERROR: New accuracy metrics not found in CSV file")
    else:
        print(f"âŒ ERROR: ML results file not found")

if __name__ == "__main__":
    verify_accuracy_metrics()